{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC Coding Challenge\n",
    "\n",
    "In this challenge, we design and implement a feature selection process that automatically discovers the best feature to use in a linear model given a training set of labeled feature vectors.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "We start   with   a   dataset   consisting   of   100,000   vectors   with   1001   dimensions.   The   values   in   each dimension   are   floating-point   numbers.   The   first   dimension   is   the  l   label    and   the   subsequent   1000 dimensions   are    features .   The   label   and   features   are   all   real-valued    random   variables    for   which the   values   in   each   vector   are    random   variants .   The   label   can   be   modeled   as   a   linear combination   of   a   subset   of   features;   i.e.,   there   is   a   simple    linear   model    for   the   label   in   terms   of certain   features.   Most   features   are    not    related   to   the   label.\n",
    "\n",
    "## Feature Selection\n",
    "Our   goal   is   to   design   and   implement   a    feature   selection   process    that   discovers   the   best features   to   use   in   a   linear   model   of   the   label   in   the   dataset   described   above.   Assume   that   a separate   process   will   use   Linear   Regression   to   produce   the   final   model   in   terms   of   the   features chosen   by   your   process.   Your   process   only   needs   to   specify   the   features   on   which   to   perform the   final   model   selection.\n",
    "\n",
    "## The Linear Regression Model\n",
    "After reducing the feature set drastically (by only considering features that are \"statistically significant\" with p values < 10^{-3}), we construct simple linear regression models to illustrate the improvment in model-training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, chi2, RFE\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the data:  (100000, 1001)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/linear_regression_challenge.csv\",\n",
    "                   sep=\"|\",\n",
    "                   header=None)\n",
    "\n",
    "print(\"Dimensions of the data: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data Into Feature-Extraction, Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of feature-learning data:  (100000, 1001)\n",
      "Dimensions of model-training data:  (90000, 1001)\n",
      "Dimensions of model-validation data:  (10000, 1001)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the data\n",
    "data = data.sample(frac=1.0, random_state=42)\n",
    "\n",
    "# data to learn significant features\n",
    "feat_data = data[:]\n",
    "X_feat = feat_data.drop(0, axis=1)\n",
    "y_feat = feat_data[0]\n",
    "\n",
    "# data to train a linear regression model\n",
    "train_data = data[: 90000]\n",
    "X_train = train_data.drop(0, axis=1)\n",
    "y_train = train_data[0]\n",
    "\n",
    "# data to test the linear regression model\n",
    "valid_data = data[90000:]\n",
    "X_valid = valid_data.drop(0, axis=1)\n",
    "y_valid = valid_data[0]\n",
    "\n",
    "print(\"Dimensions of feature-learning data: \", feat_data.shape)\n",
    "print(\"Dimensions of model-training data: \", train_data.shape)\n",
    "print(\"Dimensions of model-validation data: \", valid_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Features\n",
    "The features are NOT commensurate.  Therefore, we will normalize them using scikit-learn's \"MinMaxScaler\" which will scale all features to be in a range between 0 and 1.  The transformation is given by:\n",
    "\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the scaled feature set:  (100000, 1000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583405</td>\n",
       "      <td>0.681160</td>\n",
       "      <td>0.952492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204099</td>\n",
       "      <td>0.184882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097690</td>\n",
       "      <td>0.492290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668970</td>\n",
       "      <td>0.570888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592841</td>\n",
       "      <td>0.228362</td>\n",
       "      <td>0.631634</td>\n",
       "      <td>0.463578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.674569</td>\n",
       "      <td>0.966525</td>\n",
       "      <td>0.425462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879005</td>\n",
       "      <td>0.755205</td>\n",
       "      <td>0.519232</td>\n",
       "      <td>0.676201</td>\n",
       "      <td>0.218691</td>\n",
       "      <td>0.749504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514684</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.740817</td>\n",
       "      <td>0.336196</td>\n",
       "      <td>0.755942</td>\n",
       "      <td>0.884311</td>\n",
       "      <td>0.824636</td>\n",
       "      <td>0.360692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450182</td>\n",
       "      <td>0.877262</td>\n",
       "      <td>0.639430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901275</td>\n",
       "      <td>0.688615</td>\n",
       "      <td>0.192681</td>\n",
       "      <td>0.095179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092531</td>\n",
       "      <td>0.402710</td>\n",
       "      <td>0.503532</td>\n",
       "      <td>0.609030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.906956</td>\n",
       "      <td>0.594805</td>\n",
       "      <td>0.838676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.415988</td>\n",
       "      <td>0.374553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969008</td>\n",
       "      <td>0.742408</td>\n",
       "      <td>0.503840</td>\n",
       "      <td>0.804336</td>\n",
       "      <td>0.446704</td>\n",
       "      <td>0.470925</td>\n",
       "      <td>0.395633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425341</td>\n",
       "      <td>0.615899</td>\n",
       "      <td>0.551023</td>\n",
       "      <td>0.732308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654378</td>\n",
       "      <td>0.990732</td>\n",
       "      <td>0.877018</td>\n",
       "      <td>0.846179</td>\n",
       "      <td>0.798890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.849916</td>\n",
       "      <td>0.552855</td>\n",
       "      <td>0.953682</td>\n",
       "      <td>0.344811</td>\n",
       "      <td>0.846622</td>\n",
       "      <td>0.320495</td>\n",
       "      <td>0.201693</td>\n",
       "      <td>0.861966</td>\n",
       "      <td>0.173841</td>\n",
       "      <td>0.935148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723803</td>\n",
       "      <td>0.385278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450559</td>\n",
       "      <td>0.368364</td>\n",
       "      <td>0.955237</td>\n",
       "      <td>0.756991</td>\n",
       "      <td>0.568739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.583405  0.681160  0.952492  0.000000  0.765276  0.000000  0.072089   \n",
       "1  0.674569  0.966525  0.425462  0.000000  0.879005  0.755205  0.519232   \n",
       "2  0.599700  0.000000  0.450182  0.877262  0.639430  0.000000  0.901275   \n",
       "3  0.415988  0.374553  0.000000  0.969008  0.742408  0.503840  0.804336   \n",
       "4  0.849916  0.552855  0.953682  0.344811  0.846622  0.320495  0.201693   \n",
       "\n",
       "        7         8         9      ...          990       991       992  \\\n",
       "0  0.000000  0.204099  0.184882    ...     0.097690  0.492290  0.000000   \n",
       "1  0.676201  0.218691  0.749504    ...     0.514684  0.041401  0.740817   \n",
       "2  0.688615  0.192681  0.095179    ...     0.092531  0.402710  0.503532   \n",
       "3  0.446704  0.470925  0.395633    ...     0.425341  0.615899  0.551023   \n",
       "4  0.861966  0.173841  0.935148    ...     0.723803  0.385278  0.000000   \n",
       "\n",
       "        993       994       995       996       997       998       999  \n",
       "0  0.668970  0.570888  0.000000  0.592841  0.228362  0.631634  0.463578  \n",
       "1  0.336196  0.755942  0.884311  0.824636  0.360692  0.000000  0.766493  \n",
       "2  0.609030  0.000000  0.000000  0.990625  0.906956  0.594805  0.838676  \n",
       "3  0.732308  0.000000  0.654378  0.990732  0.877018  0.846179  0.798890  \n",
       "4  0.450559  0.368364  0.955237  0.756991  0.568739  0.000000  0.179280  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "X_feat_scaled = pd.DataFrame(min_max_scaler.fit_transform(X_feat))\n",
    "X_train_scaled = pd.DataFrame(min_max_scaler.transform(X_train))\n",
    "X_valid_scaled = pd.DataFrame(min_max_scaler.transform(X_valid))\n",
    "\n",
    "print(\"The dimensions of the scaled feature set: \", X_feat_scaled.shape)\n",
    "X_feat_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Filtering\n",
    "Assessing individual features won't scale as we increase the number of our features.  Let's try it anyway just so we can see which individual features are important and get a sense of how long it takes.\n",
    "\n",
    "To do this, we can make use of Scikit-Learn's \"f_regression\" method.  It returns the F-score as well as the \"p-value\" of the \"F-score\".  We'll use the standard that any feature with a p-value < 10^{-3} is \"significant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  [11, 332, 334, 403, 701]\n",
      "There are 5 significant features.\n",
      "\n",
      "CPU times: user 349 ms, sys: 530 ms, total: 879 ms\n",
      "Wall time: 862 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f_values = f_regression(X_feat_scaled, y_feat)\n",
    "\n",
    "significant_count = 0\n",
    "significant_idx = []\n",
    "for i in range(f_values[0].shape[0]):\n",
    "    if f_values[1][i] < 1e-3:\n",
    "        significant_count += 1\n",
    "        significant_idx.append(i)\n",
    "        \n",
    "significant_idx = np.array(significant_idx)\n",
    "     \n",
    "\n",
    "print(\"Selected Features: \", list(significant_idx))\n",
    "print(\"There are {} significant features.\".format(significant_count))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn has an extension of f_regression called \"SelectKBest\" which we can use to select (using F scores) the \"K\" best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  [11, 332, 334, 403, 701]\n",
      "\n",
      "Intersection with univariate approach:  [11, 332, 334, 403, 701]\n",
      "Percentage overlap: 100.0%\n",
      "\n",
      "CPU times: user 319 ms, sys: 5.56 ms, total: 325 ms\n",
      "Wall time: 307 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selector = SelectKBest(f_regression, k=significant_count)\n",
    "selector.fit_transform(X_feat_scaled, y_feat)\n",
    "\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "\n",
    "idxs_intersect = list(np.intersect1d(list(significant_idx), list(idxs_selected)))\n",
    "\n",
    "print(\"Selected Features: \", list(idxs_selected))\n",
    "print()\n",
    "print(\"Intersection with univariate approach: \", idxs_intersect)\n",
    "print(\"Percentage overlap: \" + str(len(idxs_intersect) / len(idxs_selected) * 100.) + \"%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use numpy to calculate mean and variance (covariance matrix)\n",
    "#def outlier_detect(x):\n",
    "#    mu = np.mean(x, axis=0)\n",
    "#    sigma = np.cov(x)\n",
    "#    return np.abs(x-x.mean())<= 3 * x.std()\n",
    "\n",
    "#X_scaled_nooutliers = X_scaled[X_scaled.apply(outlier_detect, axis=1)]\n",
    "    \n",
    "#print(X_scaled_nooutliers.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use \"Recursive Feature Elimination\" to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  [11, 332, 334, 403, 701]\n",
      "\n",
      "Intersection with univariate approach:  [ 11 332 334 403 701]\n",
      "Percentage overlap with univariate approach: 100.0%\n",
      "\n",
      "Intersection with SelectKBest approach:  [ 11 332 334 403 701]\n",
      "Percentage overlap with SelectKBest approach: 100.0%\n",
      "\n",
      "CPU times: user 23 s, sys: 4.42 s, total: 27.4 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = LinearRegression()\n",
    "num_features = significant_count\n",
    "remove_features_step = 0.5\n",
    "\n",
    "selector = RFE(estimator,\n",
    "               n_features_to_select=num_features, \n",
    "               step=remove_features_step)\n",
    "\n",
    "selector = selector.fit(X_feat_scaled, y_feat)\n",
    "\n",
    "selected = selector.ranking_ == 1\n",
    "\n",
    "idxs_selected_rfe = selected.nonzero()[0]\n",
    "\n",
    "idxs_intersect_rfe1 = np.intersect1d(list(significant_idx), list(idxs_selected_rfe))\n",
    "idxs_intersect_rfe2 = np.intersect1d(list(idxs_selected), list(idxs_selected_rfe))\n",
    "\n",
    "print(\"Selected features: \", list(idxs_selected_rfe))\n",
    "print()\n",
    "print(\"Intersection with univariate approach: \", idxs_intersect_rfe1)\n",
    "print(\"Percentage overlap with univariate approach: \" + str(np.round(len(idxs_intersect_rfe1) / len(idxs_selected) * 100., 1)) + \"%\")\n",
    "print()\n",
    "print(\"Intersection with SelectKBest approach: \", idxs_intersect_rfe2)\n",
    "print(\"Percentage overlap with SelectKBest approach: \" + str(np.round(len(idxs_intersect_rfe2) / len(idxs_selected) * 100., 1)) + \"%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Linear Regression Model\n",
    "\n",
    "Train and validate a linear regression model using both the full set of 1000 features and then the reduced set to compare and test the feature selection tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, build a model using the full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination: R^2 =  0.998963814358\n",
      "CPU times: user 15.4 s, sys: 2.15 s, total: 17.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "print(\"Coefficient of determination: R^2 = \", lr.score(X_valid_scaled, y_valid))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, build a model using the greatly-reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination: R^2 =  0.998811993654\n",
      "CPU times: user 12.2 ms, sys: 4.49 ms, total: 16.6 ms\n",
      "Wall time: 16.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_reduced = X_train_scaled[list(idxs_selected_rfe)]\n",
    "X_valid_reduced = X_valid_scaled[list(idxs_selected_rfe)]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_reduced, y_train)\n",
    "print(\"Coefficient of determination: R^2 = \", lr.score(X_valid_reduced, y_valid))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comments\n",
    "\n",
    "We see that by reducing the number of features the speed of our linear regression model is nearly 1000 times faster (while still maintaining the high performance!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
